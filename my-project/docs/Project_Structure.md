Please refine the below Prompt to instruct LLM to build the Python application robustly and error free code for execution: You are a senior full‑stack Python engineer. Build a **production‑grade full‑stack application** that solves the *Ad‑Pod Stitching Server Optimisation* problem using the **CFLP‑Heuristic** (clustering → reduced Capacitated Facility Location Problem → exact MILP).  

### Business Context
A client streams personalized ads to video‑on‑demand viewers across the United States. Ads are pre‑stitched on regional “Ad‑Pod Stitching Servers”. Each server has:
* a fixed **setup cost** (activation)
* a **capacity** (max concurrent streams)

Each Designated Market Area (DMA) has:
* a geographic location (x, y)
* a **demand** for concurrent streams

Delivery quality degrades with distance → model delivery cost as **Euclidean distance** between a server and the DMA assigned to it.

### Goal
Select a subset of servers to activate and assign every DMA to exactly one activated server, while respecting server capacities, to **minimise total cost** (setup + delivery).

### Formal Problem Definition
*Inputs* (CSV files):
- **servers.csv** → `server_id,location_x,location_y,setup_cost,capacity_streams`
- **dmas.csv** → `dma_id,location_x,location_y,demand_streams`

*Costs*:  
- **Setup** = Σ setup_cost of activated servers  
- **Delivery** = Σ EuclideanDist(server, DMA) for each assigned DMA  

*Constraints*:  
1. Every DMA assigned to exactly one active server.  
2. Σ demand_streams of DMAs assigned to a server ≤ that server’s capacity.  

*Outputs* (JSON):
- `activated_servers`: list of `server_id`  
- `assignments`: map `{dma_id → server_id}`  
- `costs`: `{total_setup_cost, total_delivery_cost, total_cost}`  

### Technical Stack (Python)
- **Backend** – FastAPI (async), Uvicorn, Pandas, NumPy, SciPy, scikit‑learn (k‑means), PuLP (or OR‑Tools) for MILP.  
- **Frontend** – Streamlit UI, Requests for API calls, Altair/Matplotlib for visualisation.  
- **Environment** – virtualenv/conda, `requirements.txt`, Docker‑compose (optional).  

### Non‑Functional Requirements
- **Scalability**: handle up to 1 000 servers and 50 000 DMAs (≈ 50 M distance entries).  
- **Performance**: end‑to‑end optimisation ≤ 30 seconds for the max scale on a typical 8‑core VM.  
- **Robustness**: graceful error handling (invalid CSV, infeasible instance, time‑outs).  
- **Code Quality**: PEP‑8, type hints, docstrings, unit tests (pytest).  
- **Reproducibility**: fixed random seeds for clustering, deterministic MILP if solver allows.  

### Deliverables
1. **Repository** with the following layout:
   ```
   project_root/
   ├─ backend/
   │   ├─ app.py                # FastAPI entry point
   │   ├─ optimization.py       # CFLP‑heuristic implementation
   │   ├─ models.py             # Pydantic schemas
   │   └─ utils.py
   ├─ frontend/
   │   ├─ app.py                # Streamlit UI
   │   └─ visualisation.py
   ├─ data/
   │   ├─ servers_sample.csv
   │   └─ dmas_sample.csv
   ├─ tests/
   │   ├─ test_backend.py
   │   └─ test_frontend.py
   ├─ Dockerfile
   ├─ docker-compose.yml
   ├─ requirements.txt
   └─ README.md
   ```

2. **API Spec** (OpenAPI schema auto‑generated by FastAPI).  
3. **README** with setup, run, and deployment instructions.  
4. **Dockerfile** + **docker‑compose.yml** for one‑click local dev (backend + frontend).  
5. **Unit & integration tests** covering happy paths, edge cases, and performance (time‑budget).  
6. **Sample run output** (using the provided small CSVs).  

### High‑Level Implementation Overview (to be expanded in later prompts)

1. **Data ingestion** (CSV → Pandas → NumPy).  
2. **Distance matrix** `D[j,i] = Euclidean(server_j, dma_i)`.  
3. **Determine feasible K range**:  
   - `K_min = ceil(total_demand / max_server_capacity)`  
   - `K_max = min(500, number_of_dmas)` (adjustable).  
4. **Loop over K values** (sampled linearly or log‑space). For each K:  
   - Run **k‑means** on DMA locations → cluster labels.  
   - **Aggregate** cluster demand and distance costs (sum of distances from all DMAs in a cluster to each server).  
   - **Formulate reduced CFLP** MILP:
     - Decision vars: `y_j ∈ {0,1}` (open server j), `x_{j,k} ∈ {0,1}` (assign cluster k).  
     - Obj: `Σ setup_cost_j * y_j + Σ agg_dist_{j,k} * x_{j,k}`.  
     - Constraints:
       - `Σ_j x_{j,k} = 1` ∀k.  
       - `Σ_k demand_k * x_{j,k} ≤ capacity_j * y_j` ∀j.  
   - Solve with **PuLP (CBC)** or **OR‑Tools** (choose free solver).  
   - **Recover** DMA‑level assignment by mapping each DMA to the server assigned to its cluster.  
   - Compute full **delivery cost** using original distances (not aggregated).  
   - Keep best solution (lowest total cost).  
5. **Return JSON** with activated servers, assignments, and cost breakdown.  

### Constraints & Edge Cases to Handle
- **Infeasible instance** (`total_server_capacity < total_demand`) → return HTTP 400 with clear message.  
- **Zero‑demand DMAs** → can be ignored or assigned arbitrarily.  
- **Duplicate IDs** or missing columns → validation error.  
- **Large data** → use `float32` for distance matrix, compute distances on‑the‑fly if memory‑tight, optional `faiss`‑like approximate nearest‑neighbors for ultra‑large N.  

### Testing & Sample Data
- Provide a **generator script** (`scripts/generate_sample_data.py`) that creates:
  - 5‑10 servers randomly placed in a 0‑100² area, capacities 100‑500, setup cost 20‑100.
  - 20‑50 DMAs with demand 1‑10, locations random.
- Include expected output for a tiny instance (e.g., 3 servers, 5 DMAs) as shown in Prompt 5.  

### Prompt for LLM to Deliver the Whole Project
> **You are to produce the complete repository described above**.  
> - Create every Python file with **docstrings**, **type hints**, and **PEP‑8** compliance.  
> - Write the **README.md** describing installation (`python -m venv venv && pip install -r requirements.txt`), usage (`uvicorn backend.app:app --reload` + `streamlit run frontend/app.py`), and Docker (`docker compose up`).  
> - Include **unit tests** that cover CSV validation, K‑range logic, MILP feasibility, and API response shapes.  
> - Provide a **Dockerfile** (multi‑stage: builder → slim) and a **docker‑compose.yml** exposing `8000` (FastAPI) and `8501` (Streamlit).  
> - Ensure **CORS** middleware permits `http://localhost:8501`.  
> - Return the full directory tree and content of each file in markdown‑code fences.  
> - Finally, run the sample data generator, invoke the API with the sample CSVs, and paste the **exact JSON response** (pretty‑printed) as a demonstration of a successful run.  
> - Do **not** include any placeholder `<TODO>` sections – every function must have a concrete implementation.  
> - Use **random_state=42** for all stochastic steps for reproducibility.  

**When the LLM finishes, you will have a complete, end‑to‑end solution ready for local testing and production deployment.**I'll refine the prompt to ensure the LLM produces a robust, production-grade Python application for the Ad-Pod Stitching Server Optimization problem. The refined prompt maintains the original structure but enhances clarity, emphasizes error handling, performance optimization, and reproducibility, and removes ambiguities to guide the LLM toward generating error-free, executable code.Refined Prompt for Ad-Pod Stitching Server Optimizationmarkdown•2.7sPlease create below list of files with detailed contents in each .md file which should have clear and detailed instruction that are used by LLM as Context Engineering for building the error free and executable Python full stack application.
Here's a comprehensive list of essential markdown files for Cursor context engineering to build error-free Python full-stack applications, with refined templates based on production best practices:

Core Context Engineering Markdown Files:

Architecture.md - System design blueprint

Implementation.md - Step-by-step build instructions

Project_Structure.md - File/directory specifications

Workflow.md - Development process automation

Error_Handbook.md - Fault tolerance system

Validation_Rules.md - Input/output contracts

Performance_SLA.md - Runtime guarantees

API_Contract.md - Interface specifications

UI_UX_Spec.md - Frontend behavior definitions

Deployment_Playbook.md - Release procedures

 ### Productive Prompt for Developing a Full-Stack Application to Solve the Ad Pod Stitching Server Optimization Problem

**Objective:**  
Create a comprehensive, step-by-step guide in the form of a prompt that outlines the detailed development process for a full-stack application. This includes a Python Streamlit frontend for user interaction and a Python FastAPI backend for performing the optimization using The CFLP‑Heuristic gives you a fast, clean, and modular solution. It keeps the core combinatorial optimisation (facility‑location) in an exact solver where it remains tractable, while the clustering step reduces the problem size dramatically. If you later need 10× the data, you can simply increase the number of clusters or use approximate clustering without changing the rest of the pipeline. This is why it is the recommended approach for the Ad‑Pod Stitching Server Optimisation problem

 The application should solve the given optimization problem, ensuring scalability for up to 1,000 servers and 50,000 DMAs. Emphasize clean code structure, error handling, and efficient libraries. At the end, provide a sample run output assuming small test data.


**Inputs were two files servers.csv and dmas.csv** 


**Business Context & Problem Statement:**  
The client delivers personalized ads in video-on-demand streams to subscribers across the US. To avoid latency and buffering, ads are pre-stitched into streams using regional Ad Pod Stitching Servers. These servers incur fixed setup costs and have capacity limits for concurrent streams. Viewers are grouped into Designated Market Areas (DMAs), each with a demand for streams and a central location. Delivery quality degrades with distance (latency risk), so delivery cost is modeled as Euclidean distance between server and DMA.

The goal is to minimize total costs (setup + delivery) by deciding which servers to activate and assigning each DMA to one activated server, without exceeding capacities.

**Formal Problem Definition:**  
- **Inputs:** Two CSV files:  
  - `servers.csv`: Columns: `server_id` (unique ID), `location_x`, `location_y` (coordinates), `setup_cost` (fixed activation cost), `capacity_streams` (max concurrent streams).  
  - `dmas.csv`: Columns: `dma_id` (unique ID), `location_x`, `location_y` (coordinates), `demand_streams` (required concurrent streams).  

- **Costs:**  
  - **Setup Cost:** Sum of `setup_cost` for activated servers.  
  - **Delivery Cost:** Sum of Euclidean distances between each DMA and its assigned server.  
  - **Total Cost:** Setup Cost + Delivery Cost.  

- **Constraints:**  
  - Each DMA must be assigned to exactly one activated server.  
  - Sum of `demand_streams` for DMAs assigned to a server ≤ server's `capacity_streams`.  

- **Output Requirements:**  
  - List of activated server_ids.  
  - Assignment mapping: Each dma_id to its assigned server_id.  
  - Cost breakdown: Total Setup Cost, Total Delivery Cost, Total Cost.  

**Algorithm Overview: Clustering-based Heuristic**  
- Use k-means clustering (from SciPy or Scikit-learn) to group DMAs into K clusters based on locations, aggregating demands and computing average or summed distances.  
- Solve a reduced Capacitated Facility Location Problem (CFLP) on the clusters using MILP (via PuLP or OR-Tools) to select servers and assign clusters.  
- Map assignments back to individual DMAs.  
- Iterate over a range of K values (e.g., from minimum required clusters to a capped maximum for scalability) and select the best (lowest cost).  
- Ensure O(N*M) operations are optimized with NumPy; for large scales, use approximate k-means variants if needed.

**Step 1: Setup Project Structure and Dependencies**  
- Create a project directory with subfolders: `frontend` for Streamlit, `backend` for FastAPI.  
- Install required libraries: `pip install streamlit fastapi uvicorn pandas numpy scipy scikit-learn pulp or-tools`.  
- Use virtual environments for isolation.  
- Include a `requirements.txt` for reproducibility.

**Step 2:  list only  the steps for implementating Python FastAPI Backend not code implementation **  
- Create `backend/app.py` as the main FastAPI file.  
- Import necessary libraries: `fastapi`, `uvicorn`, `pandas`, `numpy`, `scipy.spatial.distance`, `sklearn.cluster` (or `scipy.cluster.vq`), `pulp` (or `ortools.linear_solver`).  
- Define a POST endpoint `/optimize` that accepts two file uploads: `servers: UploadFile`, `dmas: UploadFile`.  
- Parse CSVs inside the endpoint using `pd.read_csv(io.BytesIO(await file.read()))`.  
- Extract data: server/dma locations as NumPy arrays, setup_costs, capacities, demands, IDs.  
- Compute distance matrix using `scipy.spatial.distance.cdist(server_locs, dma_locs)`.  
- Determine K range: K_min = ceil(total_demand / max_capacity), K_max = min(500, M) for scalability.  
- For each K in a sampled range (e.g., 10-20 values via linspace or steps):  
  - Perform k-means: Fit on dma_locs to get centroids and labels.  
  - Aggregate: Compute cluster_demands (sum of demands per cluster), cluster_indices (list of DMA indices per cluster).  
  - Compute aggregated distances: For each cluster, sum distances to all DMAs in it (NumPy sum along axis).  
  - Formulate reduced MILP:  
    - Variables: Binary y[j] for server activation, x[j,k] for assigning cluster k to server j.  
    - Objective: Minimize sum(setup_costs[j] * y[j]) + sum(agg_dist[j,k] * x[j,k]).  
    - Constraints: For each k, sum_j x[j,k] == 1; for each j, sum_k (cluster_demands[k] * x[j,k]) <= capacities[j] * y[j].  
    - Solve with PuLP (CBC solver) or OR-Tools.  
- Track the best solution (lowest objective value): activated servers, cluster-to-server assignments, then map back to individual DMA assignments.  
- Compute final costs: Sum setup for activated, sum individual distances for delivery.  
- Return JSON: {"activated_servers": list, "assignments": dict, "costs": {"total_setup_cost": float, "total_delivery_cost": float, "total_cost": float}}.  
- Handle errors: Validate CSV columns, check if feasible (total capacity >= total demand), return 400 Bad Request if issues.  
- For scalability: Use float32 for matrices, parallelize K loop if needed (multiprocessing), but keep single-threaded for simplicity.  
- Run the backend: `uvicorn app:app --reload`.

**Step 3: list only  the steps for implementating Python Streamlit Frontend not code implementation **  
- Create `frontend/app.py` as the main Streamlit file.  
- Import libraries: `streamlit`, `pandas`, `requests`, `json`.  
- Set page config: `st.set_page_config(page_title="Ad Server Optimizer", layout="wide")`.  
- Create UI elements:  
  - Title and description of the problem.  
  - File uploaders: `servers_file = st.file_uploader("Upload servers.csv", type="csv")`, similarly for dmas.csv.  
  - Button: `if st.button("Optimize"):`.  
- On button click:  
  - Check if files uploaded.  
  - Send POST request to backend: `response = requests.post("http://localhost:8000/optimize", files={"servers": servers_file.getvalue(), "dmas": dmas_file.getvalue()})`.  
  - Parse JSON response if status 200, else display error.  
- Display results:  
  - Use `st.subheader("Activated Servers")` and `st.write(activated_servers)`.  
  - Assignments: Convert dict to DataFrame and `st.dataframe(pd.DataFrame(list(assignments.items()), columns=["DMA ID", "Server ID"]))`.  
  - Costs: Use `st.metric` for each cost (e.g., `st.metric("Total Setup Cost", f"${costs['total_setup_cost']:.2f}")`).  
  - Add visualizations: Plot server and DMA locations with assignments (using `matplotlib` or `altair`, color by assigned server).  
- Handle loading states: Use `st.spinner("Optimizing...")` during request.  
- Add features: Download results as JSON/CSV, input for custom K range.  
- Run the frontend: `streamlit run app.py`.

**Step 4: Integration and Testing**  
- Ensure CORS in FastAPI: Add `from fastapi.middleware.cors import CORSMiddleware` and configure for localhost.  
- Test with sample data: Generate small CSVs (e.g., 5 servers, 20 DMAs) and verify outputs match manual calculations.  
- Edge cases: Insufficient capacity (error), zero demand, large data (time/memory check).  
- Deployment notes: Use Docker for containerization, NGINX for production.

**Final Solution Output:**  
For a sample run with test data (N=3 servers, M=5 DMAs):  
- Activated servers: [1, 3].  
- Assignments: {1: 1, 2: 1, 3: 3, 4: 3, 5: 1}.  
- Costs:  
  - Total Setup Cost: 220  
  - Total Delivery Cost: 25.46  
  - Total Minimized Cost: 245.46
Thought for 7sArchitecture.md - System Design Blueprint
Overview
This document serves as the high-level system design blueprint for the Ad-Pod Stitching Server Optimization application. It outlines the architectural components, data flow, and design principles to ensure a scalable, maintainable, and error-free full-stack Python application using FastAPI for the backend and Streamlit for the frontend. The design follows the CFLP-Heuristic (Clustering → Reduced Capacitated Facility Location Problem → Exact MILP) to solve the optimization problem efficiently.
Key Design Principles

Modularity: Separate concerns into backend (optimization logic) and frontend (user interaction and visualization).
Scalability: Handle up to 1,000 servers and 50,000 DMAs by using efficient data structures (NumPy arrays), memory-optimized computations (float32 for distances), and iterative clustering with a limited K-range sampling.
Error Resilience: Incorporate validation at every layer, graceful degradation for infeasible problems, and logging for diagnostics.
Performance: Target <30 seconds end-to-end for max scale on an 8-core VM through vectorized operations and timeout-bound MILP solving.
Reproducibility: Use fixed seeds (e.g., random_state=42) for clustering and deterministic solvers.
Security: Validate inputs, handle file uploads securely, and enable CORS only for trusted origins (e.g., localhost:8501).

System Components
1. Frontend (Streamlit)

Role: User interface for uploading CSV files, triggering optimization, and displaying results/visualizations.
Technologies: Streamlit, Requests (for API calls), Pandas (for data display), Altair/Matplotlib (for visualizations).
Data Flow: Upload CSVs → POST to backend → Parse JSON response → Render results (tables, metrics, plots).

2. Backend (FastAPI)

Role: API server handling optimization logic using CFLP-Heuristic.
Technologies: FastAPI (async API), Uvicorn (server), Pandas/NumPy/SciPy/scikit-learn/PuLP (optimization stack).
Data Flow: Receive CSV uploads → Validate/parse data → Compute distances → Iterate K-clustering → Solve MILP → Compute costs → Return JSON.
Endpoints:

POST /optimize: Accepts servers.csv and dmas.csv, returns JSON output.



3. Data Layer

Inputs: CSV files (servers.csv, dmas.csv) with strict column schemas.
Internal Representations: NumPy arrays for locations/distances, lists/dicts for IDs and assignments.
Outputs: JSON with activated_servers (list), assignments (dict), costs (dict).

4. Optimization Engine (CFLP-Heuristic)

Clustering: k-means on DMA locations to reduce problem size (K sampled from K_min to K_max).
Reduced CFLP: MILP formulation on clusters (PuLP with CBC solver, timeout 25s).
Assignment Recovery: Map cluster assignments back to individual DMAs, compute exact costs.
Iteration: Sample 10-20 K values, select best by total cost.

Data Flow Diagram

User uploads CSVs via Streamlit.
Streamlit sends POST to FastAPI /optimize.
FastAPI parses CSVs, validates data.
Compute distance matrix (cdist).
Determine K range, loop over samples:

Cluster DMAs (k-means).
Aggregate demands/distances.
Solve MILP (activate servers, assign clusters).
Recover DMA assignments, compute exact costs.


Select best solution, return JSON.
Streamlit renders results.

Non-Functional Aspects

Fault Tolerance: See Error_Handbook.md.
Performance Guarantees: See Performance_SLA.md.
Deployment: Containerized with Docker (see Deployment_Playbook.md).

This blueprint ensures the system is robust, efficient, and aligned with the business goal of minimizing ad delivery costs.
Implementation.md - Step-by-Step Build Instructions
Overview
This document provides a detailed, sequential guide for implementing the Ad-Pod Stitching Server Optimization application. Follow these steps to build an error-free, executable full-stack Python application. Each step includes prerequisites, actions, and verification tips. Use the CFLP-Heuristic for optimization.
Prerequisites

Python 3.10+ installed.
Create a virtual environment: python -m venv venv && source venv/bin/activate.
Install dependencies: pip install fastapi uvicorn streamlit pandas numpy scipy scikit-learn pulp requests altair.
Generate requirements.txt: pip freeze > requirements.txt.

Step 1: Set Up Project Structure

Create root directory: mkdir ad-pod-optimizer.
Add subfolders: mkdir backend frontend data tests scripts.
Refer to Project_Structure.md for exact file placements.

Step 2: Implement Backend (FastAPI)

Create backend/app.py, backend/optimization.py, backend/models.py, backend/utils.py.
In app.py: Define FastAPI app, add CORS middleware, create POST /optimize endpoint.
In optimization.py: Implement CFLP-Heuristic logic (data parsing, distance computation, K-loop with clustering and MILP).
In models.py: Use Pydantic for input/output schemas.
In utils.py: Add helpers for validation, distance calc.
Verify: Run uvicorn backend.app:app --reload, test endpoint with curl or Postman using sample CSVs.

Step 3: Implement Frontend (Streamlit)

Create frontend/app.py, frontend/visualisation.py.
In app.py: Set page config, add file uploaders, button to trigger API call, display results.
In visualisation.py: Define functions for plotting (scatter for locations, bar for costs).
Verify: Run streamlit run frontend/app.py, upload samples, check results display.

Step 4: Integrate Optimization Logic

In optimization.py:

Parse CSVs to DataFrames/arrays.
Validate (see Validation_Rules.md).
Compute distances with cdist.
Calculate K_min/K_max, sample K values.
For each K: Cluster with KMeans(random_state=42), aggregate, formulate/solve MILP with PuLP.
Select best, compute exact costs.


Handle errors: Raise exceptions for invalid data, infeasible problems.

Step 5: Add Tests

Create tests/test_backend.py, tests/test_frontend.py.
Use pytest: Test parsing, optimization, API responses, UI rendering.
Run: pytest.

Step 6: Add Sample Data Generation

Create scripts/generate_sample_data.py: Use NumPy random (seed=42) to generate CSVs in data/.

Step 7: Verify End-to-End

Generate samples.
Run backend and frontend.
Upload files, optimize, check JSON matches expected (e.g., sample output in prompt).

Step 8: Optimize for Performance

Use float32, on-the-fly computations.
Refer to Performance_SLA.md.

This guide ensures incremental, testable development leading to a production-ready application.
Project_Structure.md - File/Directory Specifications
Overview
This document specifies the exact file and directory structure for the Ad-Pod Stitching Server Optimization application. It ensures consistency, modularity, and ease of navigation for error-free development.
Directory Structure
textad-pod-optimizer/
├── backend/
│   ├── app.py                # FastAPI main entry point
│   ├── optimization.py       # CFLP-Heuristic core logic
│   ├── models.py             # Pydantic schemas for data validation
│   └── utils.py              # Helper functions (validation, distances)
├── frontend/
│   ├── app.py                # Streamlit main UI
│   └── visualisation.py      # Visualization helpers (plots, charts)
├── data/
│   ├── servers_sample.csv    # Sample servers data
│   └── dmas_sample.csv       # Sample DMAs data
├── tests/
│   ├── test_backend.py       # Pytest for backend
│   └── test_frontend.py      # Pytest for frontend
├── scripts/
│   └── generate_sample_data.py # Sample data generator
├── Dockerfile                # Docker build instructions
├── docker-compose.yml        # Multi-service composition
├── requirements.txt          # Dependencies list
└── README.md                 # Project overview and instructions
File Specifications

backend/app.py: FastAPI instance, endpoints, CORS config. ~100-200 LOC, PEP-8, type hints.
backend/optimization.py: CFLP-Heuristic implementation. ~300-500 LOC, docstrings for functions.
backend/models.py: Pydantic BaseModels for CSV schemas and JSON outputs. ~50-100 LOC.
backend/utils.py: Functions for CSV parsing, error checks, distance matrix. ~100-200 LOC.
frontend/app.py: Streamlit UI layout, API integration. ~150-300 LOC.
frontend/visualisation.py: Altair/Matplotlib plot functions. ~100-200 LOC.
data/*.csv: Generated samples; servers: 5-10 rows, DMAs: 20-50 rows.
tests/*.py: Pytest cases covering 80%+ code; include mocks for API.
scripts/generate_sample_data.py: NumPy-based generator with seed=42. ~50-100 LOC.
Dockerfile: Multi-stage build (builder + runtime).
docker-compose.yml: Services for backend (8000) and frontend (8501).
requirements.txt: Exact versions, e.g., fastapi==0.100.0.
README.md: Setup, run, deploy instructions.

Adhere strictly to this structure to avoid integration errors.